---
title: "hw8"
output:
  pdf_document: default
  html_document: default
date: "2024-03-29"
---

# 2a

```{r}
library(dplyr)
library(MASS) 
```

```{r}
Y <- read.table("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/azdiabetes.dat", header=TRUE)
diabetics <- Y %>%
  filter(diabetes=="Yes")
Y_d <- diabetics[, 1:7]
nondiabetics <- Y %>%
  filter(diabetes=="No")
Y_n <- nondiabetics[, 1:7]
```

```{r}
mu0_d <- colMeans(diabetics[, 1:7])
samp_cov_d <- cov(diabetics[, 1:7])
lambda0_d <- cov(diabetics[, 1:7])
S0_d <- samp_cov_d
nu0_d <- 9

mu0_n <- colMeans(nondiabetics[, 1:7])
samp_cov_n <- cov(nondiabetics[, 1:7])
lambda0_n <- cov(nondiabetics[, 1:7])
S0_n <- samp_cov_n
nu0_n <- 9
```

```{r}
### Simulate multivariate normal vector
rmvnorm<-function(n,mu,Sigma)
{
  p<-length(mu)
  res<-matrix(0,nrow=n,ncol=p)
  if(n>0 & p>0) 
  {
    E<-matrix(rnorm(n*p),n,p)
    res<-t(  t(E%*%chol(Sigma)) +c(mu))
  }
  res
}

### Simulate from the Wishart distribution
rwish<-function(n,nu0,S0)
{
  sS0 <- chol(S0)
  S<-array( dim=c( dim(S0),n ) )
  for(i in 1:n)
  {
     Z <- matrix(rnorm(nu0 * dim(S0)[1]), nu0, dim(S0)[1]) %*% sS0
     S[,,i]<- t(Z)%*%Z
  }
  S[,,1:n]
}

```

```{r}
### Gibbs sampler

Sigma_d <- samp_cov_d
n_d<-dim(Y_d)[1]
S0_d <- samp_cov_d
THETA_d <- NULL
SIGMA_d <- NULL

Sigma_n <- samp_cov_n
n_n<-dim(Y_n)[1]
S0_n <- samp_cov_n
THETA_n <- NULL
SIGMA_n <- NULL

S <- 500

for (s in 1:S){
    ###update theta_d
  Ln_d<-solve( solve(lambda0_d) + n_d*solve(Sigma_d) )
  mun_d<-Ln_d%*%( solve(lambda0_d)%*%mu0_d + n_d*solve(Sigma_d)%*%mu0_d )
  theta_d<-rmvnorm(1,mun_d,Ln_d)
  ###
  
    ###update Sigma_d
  Sn_d<- S0_d + ( t(Y_d)-c(theta_d) )%*%t( t(Y_d)-c(theta_d) )
  Sigma_d<-solve( rwish(1, nu0_d+n_d, solve(Sn_d)) )
  ###
  
    ### save results
  THETA_d<-rbind(THETA_d,theta_d) ; SIGMA_d<-rbind(SIGMA_d,c(Sigma_d))
  ###
  
  
  
  
  
      ###update theta_n
  Ln_n<-solve( solve(lambda0_n) + n_n*solve(Sigma_n) )
  mun_n<-Ln_n%*%( solve(lambda0_n)%*%mu0_n + n_n*solve(Sigma_n)%*%mu0_n )
  theta_n<-rmvnorm(1,mun_n,Ln_n)
  ###
  
    ###update Sigma_n
  Sn_n<- S0_n + ( t(Y_n)-c(theta_n) )%*%t( t(Y_n)-c(theta_n) )
  Sigma_n<-solve( rwish(1, nu0_d+n_n, solve(Sn_n)) )
  ###
  
    ### save results
  THETA_n<-rbind(THETA_n,theta_n) ; SIGMA_n<-rbind(SIGMA_n,c(Sigma_n))
  ###
  
  if (s %% 100 == 0){
    print(s)
  }
  
}

```

```{r}
colMeans(THETA_n) - colMeans(THETA_d)
```

```{r}
apply(THETA_n, 2, var) - apply(THETA_d, 2, var)
```

The glucose of diabetics seems to be, on average, much higher than that of non-diabetics. Additionally, the variance of glucose is much greater for diabetics than it is for non-diabetics.

```{r}
colMeans(THETA_d > THETA_n)
```

$Pr(\theta_{d,j} > \theta_{n,j}|Y) = 1$ for all j $\in$ {1, 2, 3, 4, 5, 6, 7}.

# 2b

```{r}
colMeans(SIGMA_n) - colMeans(SIGMA_d)
```
The 2,2 entry corresponds to glucose, so this supports our observation that the variability in glucose is especially high in diabetics. 

```{r}
plot(colMeans(SIGMA_n), colMeans(SIGMA_d), 
     xlab = "Posterior Mean of Covariance Matrix 1",
     ylab = "Posterior Mean of Covariance Matrix 2",
     main = "Posterior Means of Covariance Matrices",
     pch = 19, col = "blue")
```

```{r}
library(knitr)

#### Function for posterior quantile intervals for matrices
#### From the `sbgcop` package
plotci.sA<-function(sA, ylabs = colnames(sA[, , 1]), mgp = c(1.75, 0.75, 
    0)) 
{
    qA <- qM.sM(sA)
    p <- dim(qA)[1]
    tmp <- c(qA)
    tmp <- tmp[tmp != 1]
    par(mgp = mgp)
    for (j in 1:p) {
        plot(0, 0, type = "n", ylim = range(c(tmp), na.rm = TRUE), 
            xlim = c(1, p), ylab = ylabs[j], xaxt = "n", xlab = "")
        points((1:p)[-j], qA[j, -j, 2], pch = 16, cex = 0.6)
        segments(x0 = (1:p)[-j], y0 = qA[j, -j, 1], x1 = (1:p)[-j], 
            y1 = qA[j, -j, 3])
        abline(h = 0, col = "gray")
        abline(v = j, col = "gray")
    }
    axis(side = 1, at = 1:p, labels = colnames(qA[, , 1]), las = 2)
}

sR.sC<-function(sC) 
{
    p <- dim(sC)[1]
    s <- dim(sC)[3]
    sR <- array(dim = c(p, p, s))
    dimnames(sR) <- dimnames(sC)
    for (l in 1:s) {
        C <- sC[, , l]
        R <- C * NA
        for (j in 1:p) {
            R[j, -j] <- C[j, -j] %*% solve(C[-j, -j])
        }
        sR[, , l] <- R
    }
    sR
}

qM.sM<-function (sM, quantiles = c(0.025, 0.5, 0.975)) 
{
    p1 <- dim(sM)[1]
    p2 <- dim(sM)[2]
    s <- dim(sM)[3]
    qM <- array(dim = c(p1, p2, length(quantiles)))
    dimnames(qM) <- list(dimnames(sM)[[1]], dimnames(sM)[[2]], 
        paste(quantiles * 100, rep("% quantile", length(quantiles)), 
            sep = ""))
    for (l in 1:length(quantiles)) {
        qM[, , l] <- apply(sM, c(1, 2), quantile, prob = quantiles[l], 
            na.rm = TRUE)
    }
    qM
}

######



p <- 7

COR <- array( dim=c(p,p,S) ) 

for(s in 1:S){
Sig <- matrix( SIGMA_d[s,] ,nrow=p,ncol=p)
COR[ , ,s] <- Sig/sqrt( outer( diag(Sig),diag(Sig) ) )
}

apply(COR, c(1,2), quantile,prob=c(.025,.975))

pdf("cor_graph.pdf",height=6,width=6,family="Times")

par(mfcol=c(7,2),mar=c(1,2.75,1,1),mgp=c(1.75,.75,0),oma=c(1.5,0,0,0))


plotci.sA(COR)

REG<-sR.sC(COR)
plotci.sA(REG)
dev.off()


CQ<-apply(COR, c(1,2), quantile,prob=c(.025,.5,.975) )

round(CQ[1,,],2)
round(CQ[2,,],2)
round(CQ[3,,],2)

round(apply(COR,c(1,2),mean),2)


```

```{r}
knitr::include_graphics("cor_graph.pdf")
```

There do not seem to be many significant differences between the two groups. One difference we see is that

# 4

```{r}
Y<-dget(url("http://www2.stat.duke.edu/~pdh10/FCBS/Inline/Y.pima.miss"))
```

```{r}
Y=Y%>%
  filter(!is.na(glu))%>%
  filter(!is.na(bp))%>%
  filter(!is.na(skin))%>%
  filter(!is.na(bmi))
colMeans(Y)
```

```{r}
###
Y <- readRDS("hw8train.rds")
```

```{r}
### prior parameters 
n<-dim(Y)[1] ; p<-dim(Y)[2]
mu0<-c(rep(0,14))
sd0<-(mu0/2)
L0<-matrix(.1,p,p) ; diag(L0)<-1 ; L0<-L0*outer(sd0,sd0)
nu0<-p+2 ; S0<-L0
###

### starting values
Sigma<-S0
Y.full<-Y
O<-1*(!is.na(Y))
```
